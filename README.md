# Retail Pipeline â€” Airflow + DBT + PostgreSQL

This project is an end-to-end retail analytics pipeline built with:

- **Apache Airflow** â€“ Workflow orchestration  
- **dbt (Data Build Tool)** â€“ Data transformation  
- **PostgreSQL** â€“ Local data warehouse  
- **Docker/Podman Compose** â€“ Containerized environment  

It simulates a modern data engineering architecture from raw ingestion to analytics outputs.

---

## ğŸš€ Architecture Overview


![Alt Text](data/img/arc.png)

---

## ğŸ“ Project Structure

```
poc/
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/                  
â”‚   â”œâ”€â”€ logs/
â”‚   â””â”€â”€ plugins/
â”‚
â”œâ”€â”€ data/                      
â”‚
â”œâ”€â”€ dbt/
â”‚   â””â”€â”€ retail_project/
â”‚       â””â”€â”€ retail_project/
â”‚           â”œâ”€â”€ models/
â”‚           â”‚   â”œâ”€â”€ staging/         
â”‚           â”‚   â”œâ”€â”€ marts/           
â”‚           â”‚   â”œâ”€â”€ analytics/       
â”‚           â”‚   â””â”€â”€ sources.yml
â”‚           â””â”€â”€ dbt_project.yml
â”‚
â”œâ”€â”€ postgres/
â”‚   â””â”€â”€ data/                  
â”‚
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ Dockerfile
```

---

## ğŸ³ Running the Pipeline (Docker/Podman Compose)

### 1. Build the custom Airflow image (includes dbt)
```bash
podman build -t poc-airflow .
```

### 2. Start all services
```bash
podman-compose up -d
```

### 3. Web UIs
- **Airflow UI:** http://localhost:8082  
- **PostgreSQL:** accessible via port `55432`

---

## ğŸ› ï¸ Airflow DAGs

### Ingestion DAGs
- `ingest_customers_raw.py`
- `ingest_products_raw.py`
- `ingest_sales_raw.py`
- `ingest_stores_raw.py`

### dbt Pipeline DAG
- `dbt_full_pipeline.py`  
  Executes:
  - `dbt deps`
  - `dbt run`
  - `dbt test`

---

## ğŸ§± DBT Models Overview

### **1. Staging Layer (`staging.`)**  
Cleans raw data, renames fields, casts data types.

### **2. Mart Layer (`mart.`)**  
Star-schema style dimensional modeling:
- `dim_customer`
- `dim_product`
- `dim_store`
- `fact_sales`

### **3. Analytics Layer (`analytics.`)**  
Higher-level analytical models:
- `customer_features` â€“ tenure, total tx, total spent
- `daily_sales_kpi` â€“ daily sales KPI summary
- `daily_store_sales` â€“ store-level daily metrics

---

## ğŸ”§ PostgreSQL Connection Info

Use the following settings (example for DBeaver):

```
Host: localhost
Port: 55432
User: airflow
Password: airflow_pass
Database: retail_dwh
```

Schemas used:
- `raw`
- `staging`
- `mart`
- `analytics`

---

## ğŸ—‚ï¸ .gitignore

Generated or large directories intentionally excluded:
- `airflow/logs/`
- `postgres/data/`
- `dbt/**/target/`
- `dbt/**/dbt_packages/`
- `__pycache__/`

---
